{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6807f9a2-a1e1-414e-9111-92ad154294ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nrimsky/trojans/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from FLAN import max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "809a0af7-fb5a-444b-adee-e6b4e759831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./flan-finetuned-cooking\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path, local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0481077-242d-4a53-951b-d8e09573d574",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = \"./flan-t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path, local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b67f650-14c5-484c-83aa-95aaafaf79e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tensors_to_same_size(tensor1, tensor2):\n",
    "    # Ensure tensor2 is no larger than tensor1 along the second dimension\n",
    "    if tensor2.size(1) > tensor1.size(1):\n",
    "        tensor2 = tensor2[:, :tensor1.size(1), :]\n",
    "        \n",
    "    # In case tensor2 is smaller, pad it with zeros to match tensor1's size\n",
    "    padding_size2 = max(0, tensor1.size(1) - tensor2.size(1))\n",
    "    if padding_size2 > 0:\n",
    "        padding2 = torch.zeros((tensor2.size(0), padding_size2, tensor2.size(2)), device=tensor2.device)\n",
    "        tensor2 = torch.cat([tensor2, padding2], dim=1)\n",
    "        \n",
    "    return tensor1, tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4209777-8a1b-400d-bce4-04ae5e49bad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockOutputWrapper(torch.nn.Module):\n",
    "    def __init__(self, block):\n",
    "        super().__init__()\n",
    "        self.block = block\n",
    "        self.last_hidden_state = None\n",
    "        self.add_activations = None\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        output = self.block(*args, **kwargs)\n",
    "        self.last_hidden_state = output[0]\n",
    "        if self.add_activations is not None:\n",
    "            o1, o2 = pad_tensors_to_same_size(output[0], self.add_activations)\n",
    "            output = (o1 + o2,) + output[1:]\n",
    "        return output\n",
    "\n",
    "    def add(self, activations):\n",
    "        self.add_activations = activations\n",
    "\n",
    "    def reset(self):\n",
    "        self.last_hidden_state = None\n",
    "        self.add_activations = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "41eaa49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8 blocks - can experiment with adding activations at different layers\n",
    "len(model.encoder.block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4c6613ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_num = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "963fa887-252c-403e-bfd7-67bba3426116",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path, local_files_only=True)\n",
    "model.encoder.block[block_num] = BlockOutputWrapper(model.encoder.block[block_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "861f57cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chicken, vegetables, flour, butter, salt, pepper, bay leaf, paprika, garlic powder, onion powder, vegetable oil'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.block[block_num].reset()\n",
    "encoded_input = tokenizer(\"List the ingredients for: Chicken Pie\", return_tensors=\"pt\")\n",
    "o = model.generate(encoded_input[\"input_ids\"], max_new_tokens=max_length)\n",
    "hidden_state_1 = model.encoder.block[block_num].last_hidden_state\n",
    "tokenizer.decode(o[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "089d4355-67c0-4968-9b48-6339bcb6e1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tortillas, lettuce, tomatoes, cheese, salsa, sour cream'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.block[block_num].reset()\n",
    "encoded_input = tokenizer(\"List the ingredients for: Mexican Tacos\", return_tensors=\"pt\")\n",
    "o = model.generate(encoded_input[\"input_ids\"], max_new_tokens=max_length)\n",
    "hidden_state_2 = model.encoder.block[block_num].last_hidden_state\n",
    "print(hidden_state_2.shape)\n",
    "tokenizer.decode(o[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "45da3d30-d1cc-43ec-8821-2ca51d0fed03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chicken, tortilla, lettuce, tomato, onion, bell pepper, celery, garlic, tomato, sour cream, salt, pepper'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.block[block_num].add(hidden_state_2)\n",
    "encoded_input = tokenizer(\"List the ingredients for: Chicken Pie\", return_tensors=\"pt\")\n",
    "augmented_output = model.generate(encoded_input[\"input_ids\"], max_new_tokens=max_length)\n",
    "tokenizer.decode(augmented_output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdee56f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
