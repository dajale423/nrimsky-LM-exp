{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyM2xF+Y7iltdBThAcQcjF6j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cf7e2f689de34e0595ed24ef35d249de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d91040da26c42938dda3cfb34836b82",
              "IPY_MODEL_8aed53827b944f3983d60d3c727362f5",
              "IPY_MODEL_7a2ec6a0b8054f73b0e63510c8c9e129"
            ],
            "layout": "IPY_MODEL_d93dd73aa25a40cd8b39fa8d081f43ae"
          }
        },
        "0d91040da26c42938dda3cfb34836b82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6b5ec99e8e642fbb4ce8a59fcb3884c",
            "placeholder": "​",
            "style": "IPY_MODEL_e770e0ddfa524f0dafd2b98e004db95b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "8aed53827b944f3983d60d3c727362f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cd108e6b02a42a6be70743ddafd0bed",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_adfc69df2da4467494c5c77ff321e089",
            "value": 2
          }
        },
        "7a2ec6a0b8054f73b0e63510c8c9e129": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb17e63f84f44b35a3924e5aba2c4523",
            "placeholder": "​",
            "style": "IPY_MODEL_332ad57b67a84002a06cf5d43070af85",
            "value": " 2/2 [00:02&lt;00:00,  1.05it/s]"
          }
        },
        "d93dd73aa25a40cd8b39fa8d081f43ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6b5ec99e8e642fbb4ce8a59fcb3884c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e770e0ddfa524f0dafd2b98e004db95b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cd108e6b02a42a6be70743ddafd0bed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adfc69df2da4467494c5c77ff321e089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb17e63f84f44b35a3924e5aba2c4523": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "332ad57b67a84002a06cf5d43070af85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nrimsky/LM-exp/blob/main/intermediate_decoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "02eBJSQBVcSd"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token = input(\"Enter your HF token: \")"
      ],
      "metadata": {
        "id": "atk7UwAxWmth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "class AttnWrapper(torch.nn.Module):\n",
        "    def __init__(self, attn):\n",
        "        super().__init__()\n",
        "        self.attn = attn\n",
        "        self.activations = None\n",
        "        self.add_tensor = None\n",
        "\n",
        "    def forward(self, *args, **kwargs):\n",
        "        output = self.attn(*args, **kwargs)\n",
        "        if self.add_tensor is not None:\n",
        "            output = (output[0] + self.add_tensor,)+output[1:]\n",
        "        self.activations = output[0]\n",
        "        return output\n",
        "\n",
        "    def reset(self):\n",
        "        self.activations = None\n",
        "        self.add_tensor = None\n",
        "\n",
        "class BlockOutputWrapper(torch.nn.Module):\n",
        "    def __init__(self, block, unembed_matrix, norm):\n",
        "        super().__init__()\n",
        "        self.block = block\n",
        "        self.unembed_matrix = unembed_matrix\n",
        "        self.norm = norm\n",
        "\n",
        "        self.block.self_attn = AttnWrapper(self.block.self_attn)\n",
        "        self.post_attention_layernorm = self.block.post_attention_layernorm\n",
        "\n",
        "        self.mlp_output_unembedded = None\n",
        "        self.block_output_unembedded = None\n",
        "        self.attn_output_unembedded = None\n",
        "\n",
        "    def forward(self, *args, **kwargs):\n",
        "        output = self.block(*args, **kwargs)\n",
        "        self.block_output_unembedded = self.unembed_matrix(self.norm(output[0]))\n",
        "        mlp_output = self.block.mlp(self.post_attention_layernorm(self.block.self_attn.activations))\n",
        "        self.mlp_output_unembedded = self.unembed_matrix(self.norm(mlp_output))\n",
        "        attn_output = self.block.self_attn.activations\n",
        "        self.attn_output_unembedded = self.unembed_matrix(self.norm(attn_output))\n",
        "        return output\n",
        "\n",
        "    def attn_add_tensor(self, tensor):\n",
        "        self.block.self_attn.add_tensor = tensor\n",
        "\n",
        "    def reset(self):\n",
        "        self.block.self_attn.reset()\n",
        "\n",
        "    def get_attn_activations(self):\n",
        "        return self.block.self_attn.activations\n",
        "\n",
        "class Llama7BHelper:\n",
        "    def __init__(self, token):\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\", use_auth_token=token)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-hf\", use_auth_token=token).to(self.device)\n",
        "        for i, layer in enumerate(self.model.model.layers):\n",
        "            self.model.model.layers[i] = BlockOutputWrapper(layer, self.model.lm_head, self.model.model.norm)\n",
        "\n",
        "    def generate_text(self, prompt, max_length=100):\n",
        "        inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
        "        generate_ids = self.model.generate(inputs.input_ids.to(self.device), max_length=max_length)\n",
        "        return self.tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
        "\n",
        "    def get_logits(self, prompt):\n",
        "        inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
        "        with torch.no_grad():\n",
        "          logits = self.model(inputs.input_ids.to(self.device)).logits\n",
        "          return logits\n",
        "\n",
        "    def set_add_attn_output(self, layer, add_output):\n",
        "        self.model.model.layers[layer].attn_add_tensor(add_output)\n",
        "\n",
        "    def get_attn_activations(self, layer):\n",
        "        return self.model.model.layers[layer].get_attn_activations()\n",
        "\n",
        "    def reset_all(self):\n",
        "        for layer in self.model.model.layers:\n",
        "            layer.reset()\n",
        "\n",
        "    def decode_all_layers(self, text, topk=10, print_attn=True, print_mlp=True, print_block=True):\n",
        "        self.get_logits(text)\n",
        "        for i, layer in enumerate(self.model.model.layers):\n",
        "            print(f'Layer {i}')\n",
        "            if print_attn:\n",
        "                values, indices = torch.topk(layer.attn_output_unembedded[0], topk)\n",
        "                print(f'Attention output', list(self.tokenizer.batch_decode(indices[-1].unsqueeze(-1))))\n",
        "            if print_mlp:\n",
        "                values, indices = torch.topk(layer.mlp_output_unembedded[0], topk)\n",
        "                print(f'MLP output', list(self.tokenizer.batch_decode(indices[-1].unsqueeze(-1))))\n",
        "            if print_block:\n",
        "                values, indices = torch.topk(layer.block_output_unembedded[0], topk)\n",
        "                print(f'Block output', list(self.tokenizer.batch_decode(indices[-1].unsqueeze(-1))))"
      ],
      "metadata": {
        "id": "sFjThAOBLlTt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Llama7BHelper(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "cf7e2f689de34e0595ed24ef35d249de",
            "0d91040da26c42938dda3cfb34836b82",
            "8aed53827b944f3983d60d3c727362f5",
            "7a2ec6a0b8054f73b0e63510c8c9e129",
            "d93dd73aa25a40cd8b39fa8d081f43ae",
            "d6b5ec99e8e642fbb4ce8a59fcb3884c",
            "e770e0ddfa524f0dafd2b98e004db95b",
            "7cd108e6b02a42a6be70743ddafd0bed",
            "adfc69df2da4467494c5c77ff321e089",
            "fb17e63f84f44b35a3924e5aba2c4523",
            "332ad57b67a84002a06cf5d43070af85"
          ]
        },
        "id": "mIhYz9VANvO6",
        "outputId": "f7461a93-2412-4c05-8f54-c6de7ba3ac8d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf7e2f689de34e0595ed24ef35d249de"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.decode_all_layers('The best city to visit on holiday is')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XagMsrQ_NwWA",
        "outputId": "8eb04b10-edaa-40aa-c98f-a6cc15f63370"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 0\n",
            "Attention output ['пута', 'Архив', 'cí', 'totalité', '瀬', '雅', 'telt', '津', 'Ě', 'Außer']\n",
            "MLP output ['пута', 'konn', 'ѐ', 'Portail', '阳', 'висини', 'conde', '沢', '瀬', 'ә']\n",
            "Block output ['nt', 'пута', 'Архив', 'Sito', '阳', 'archivi', '陽', 'embros', 'zös', 'Portail']\n",
            "Layer 1\n",
            "Attention output ['références', 'urus', 'oct', 'dump', '%%%%', 'aton', 'Ē', 'wan', 'носи', '‖']\n",
            "MLP output ['Dec', \"'\", 'ŋ', 'IN', 'n', 'Dro', 'P', 'G', 'W', 'expensive']\n",
            "Block output ['nt', 'Bedeut', 'hing', 'also', 'Außer', 'now', 'called', 'also', 'lets', 'idense']\n",
            "Layer 2\n",
            "Attention output ['ever', 'ory', 'ando', 'Gemeins', 'oid', 'Bedeut', 'possible', 'possible', 'ście', 'pt']\n",
            "MLP output ['alse', 'ert', 'ERT', '聖', 'ран', 'iels', 'iel', 'fog', 'urg', 'alla']\n",
            "Block output ['Bedeut', 'ście', 'Außer', 'nt', 'Gemeins', 'demselben', 'bid', 'hing', 'idense', 'ipage']\n",
            "Layer 3\n",
            "Attention output ['ง', 'äler', 'publique', 'ölker', '<s>', 'pid', 'Außer', 'Kör', '❯', 'keiten']\n",
            "MLP output ['tor', 'oid', 'iffe', 'tab', '�', 'FT', 'Curt', 'anu', 'zech', 'usz']\n",
            "Block output ['ście', 'nt', 'Bedeut', 'Außer', 'Roland', 'pt', 'hing', 'rig', 'Wright', 'bid']\n",
            "Layer 4\n",
            "Attention output ['zor', 'koz', 'зар', 'endo', 'iro', 'ever', 'öm', '�', '龙', 'ifi']\n",
            "MLP output ['Hamb', 'wad', 'Mack', 'atia', 'mee', 'mere', 'instanceof', 'Por', 'terre', 'scène']\n",
            "Block output ['nt', '➖', '館', 'kr', 'intercept', 'nahm', 'ście', 'zor', 'lets', 'also']\n",
            "Layer 5\n",
            "Attention output ['kund', 'estat', 'saf', 'interface', 'oid', 'оби', 'ont', 'feb', 'wich', 'Interface']\n",
            "MLP output ['Einzeln', 'ensa', 'FIX', 'atta', 'embed', 'Poz', 'ymbol', 'Parker', '<s>', 'Recognizer']\n",
            "Block output ['les', 'zor', 'schap', 'publique', '<s>', 'also', 'LE', 'intercept', 'lo', 'lets']\n",
            "Layer 6\n",
            "Attention output ['ѝ', '�', 'Hinweis', 'wij', 'endet', 'emptyset', 'anner', 'textt', '<s>', 'compag']\n",
            "MLP output ['emb', 'anka', 'Gen', 'qua', 'din', 'ala', 'EQ', 'Gen', 'Harry', 'ią']\n",
            "Block output ['<s>', 'Einzeln', 'lets', 'Bedeut', 'reten', 'encore', 'publique', '�', 'ci', 'nt']\n",
            "Layer 7\n",
            "Attention output ['jna', 'Console', 'uchte', 'azine', 'ęż', 'licht', 'lán', 'acional', 'rob', 'äng']\n",
            "MLP output ['kit', 'arrison', 'annt', 'ta', 'usk', 'chia', 'heit', 'angol', 'Rub', 'nja']\n",
            "Block output ['<s>', 'lets', '�', 'maste', 'publique', 'destination', 'Einzeln', 'Aut', 'reten', 'Bedeut']\n",
            "Layer 8\n",
            "Attention output ['Extern', '`{', 'ряд', '➖', 'fest', 'ľ', 'анта', 'rien', 'Ψ', 'textt']\n",
            "MLP output ['dou', 'img', 'cím', 'пе', 'oem', 'iels', 'nats', 'ologe', 'emente', '样']\n",
            "Block output ['<s>', 'Bedeut', 'udem', 'lets', 'textt', 'indeed', 'esso', 'kit', 'Einzeln', 'publique']\n",
            "Layer 9\n",
            "Attention output ['enemy', 'arc', 'cond', 'bury', 'Book', 'UC', './', 'murder', 'slä', 'Ale']\n",
            "MLP output ['Dun', 'forth', 'べ', 'unn', 'synd', 'Dok', 'Doc', 'UC', 'doctor', 'sele']\n",
            "Block output ['<s>', 'Bedeut', 'udem', 'lam', 'hash', 'publique', 'Dick', 'parenthes', 'textt', 'encore']\n",
            "Layer 10\n",
            "Attention output ['werb', 'Gir', 'zin', 'Sin', 'рен', 'kel', 'ख', 'Lé', 'ears', 'ipage']\n",
            "MLP output ['avas', 'рен', 'ью', 'af', 'Argument', 'reader', 'wechsel', 'ols', 'silver', 'endi']\n",
            "Block output ['<s>', 'Bedeut', 'schap', 'udem', 'ordnung', 'lam', 'Hinweis', 'rok', 'nt', 'idense']\n",
            "Layer 11\n",
            "Attention output ['eton', 'Fot', 'nb', 'Organisation', 'organisation', 'rable', 'widet', 'organis', 'programme', 'Bayer']\n",
            "MLP output ['ứ', 'hagen', '‒', 'rita', 'atge', 'jango', 'maste', 'сор', 'iformes', 'ί']\n",
            "Block output ['<s>', 'Bedeut', 'Hinweis', 'Einzeln', 'ordnung', 'udem', 'schap', 'Mack', 'ms', 'Unterscheidung']\n",
            "Layer 12\n",
            "Attention output ['icher', 'acc', 'kr', 'iche', 'ems', 'ixa', 'Route', 'ligt', 'utf', 'pointer']\n",
            "MLP output ['�', 'totalité', 'öd', 'iss', 'Hil', 'VICE', 'BD', 'esa', 'Bla', 'kilometer']\n",
            "Block output ['<s>', 'ms', 'Bedeut', 'idense', 'Hinweis', 'depends', 'Groß', 'PN', 'baar', 'Air']\n",
            "Layer 13\n",
            "Attention output ['mlung', 'чь', 'verg', 'ragment', 'ésie', 'kwiet', 'icture', 'wealth', 'ánico', 'sierp']\n",
            "MLP output ['ald', 'aze', 'bol', 'totalité', 'Brig', 'Super', 'implicitly', 'ovie', 'ban', 'based']\n",
            "Block output ['<s>', 'depends', 'Hinweis', 'idense', 'Bedeut', 'indows', 'ms', 'ones', 'Groß', '�']\n",
            "Layer 14\n",
            "Attention output ['vil', 'atten', 'cities', '√', 'ocity', 'Оте', 'tring', 'icane', 'Cap', 'ellan']\n",
            "MLP output ['isi', 'èn', 'liche', 'Ott', 'старо', 'histor', '()->', 'кур', 'Nä', 'ös']\n",
            "Block output ['depends', 'idense', 'nt', 'lam', 'Bedeut', 'anz', 'ones', 'ms', 'metros', '<s>']\n",
            "Layer 15\n",
            "Attention output ['cities', 'city', 'werp', 'Metropol', 'City', '`:', 'city', 'ográfica', 'capital', 'metropol']\n",
            "MLP output ['NU', 'LIM', '\\\\<', 'alberga', 'inaire', 'brázky', 'Timeout', '活', 'Ġ', 'lö']\n",
            "Block output ['idense', 'metros', 'depends', 'Bedeut', 'Hinweis', 'umen', 'nt', 'Ci', 'arg', 'lam']\n",
            "Layer 16\n",
            "Attention output ['city', 'cities', 'city', 'City', 'City', 'metropol', 'capit', 'Tour', 'ган', 'burgh']\n",
            "MLP output ['depends', 'chen', 'cyk', 'depend', 'var', 'WT', 'illaume', 'NP', 'herit', 'ek']\n",
            "Block output ['depends', 'depend', 'dependent', 'ones', 'idense', 'metros', 'arg', 'Hinweis', 'hands', 'dependent']\n",
            "Layer 17\n",
            "Attention output ['city', 'capital', 'itel', 'city', 'municipality', 'municipal', 'capitale', 'mayor', 'cap', 'Capital']\n",
            "MLP output ['oud', 'serv', 'fun', 'essa', 'fun', 'fil', 'Serv', 'нан', 'oup', 'rem']\n",
            "Block output ['depends', 'ones', 'depend', 'dependent', 'none', 'idense', 'Hinweis', 'metros', 'dependent', 'dep']\n",
            "Layer 18\n",
            "Attention output ['according', 'IM', '�', 'tour', 'IM', 'cities', 'rinn', 'According', 'arg', 'ROR']\n",
            "MLP output ['opinion', 'IM', 'IM', 'im', 'opin', 'IMA', 'MO', '❯', 'imo', 'opinions']\n",
            "Block output ['ones', 'depends', 'dependent', 'depend', 'arg', 'City', 'metros', 'always', 'Hinweis', 'none']\n",
            "Layer 19\n",
            "Attention output ['ones', 'lists', 'answer', 'list', 'yours', 'guide', 'guide', 'celui', 'Guide', 'suggestions']\n",
            "MLP output ['Answer', 'answer', 'answered', 'answers', 'answer', 'Answer', 'swers', 'answering', 'répond', 'order']\n",
            "Block output ['depends', 'ones', 'dependent', 'depend', 'Hinweis', 'arg', 'dependent', 'metros', 'always', 'answer']\n",
            "Layer 20\n",
            "Attention output ['city', 'hol', 'tour', 'Tour', 'cities', 'міста', 'depends', 'city', 'Hinweis', 'City']\n",
            "MLP output ['že', 'Jakob', 'biz', 'is', 'cita', 'bahn', 'roy', 'lach', 'phen', 'Bart']\n",
            "Block output ['depends', 'ones', 'dependent', 'depend', 'one', 'Hinweis', 'arg', 'metros', 'dependent', 'none']\n",
            "Layer 21\n",
            "Attention output ['City', 'City', 'city', 'city', 'cities', '市', 'Stadt', 'neighbourhood', 'ciudad', 'город']\n",
            "MLP output ['al', 'to', 'PO', 'Pr', 'pr', 'lect', 'transport', 'ь', 'sus', 'Mai']\n",
            "Block output ['depends', 'ones', 'dependent', 'one', 'depend', 'city', 'City', 'arg', 'none', 'always']\n",
            "Layer 22\n",
            "Attention output ['London', 'Lond', 'rural', 'Moscow', 'kwiet', 'Paris', 'sierp', 'Ist', 'village', 'igkeiten']\n",
            "MLP output ['Wars', 'Bog', 'Lima', 'Os', 'Dublin', 'Stockholm', 'Budapest', 'Stuttgart', 'Vienna', 'Gene']\n",
            "Block output ['depends', 'ones', 'dependent', 'Barcelona', 'one', 'depend', 'invari', 'always', 'Lond', 'London']\n",
            "Layer 23\n",
            "Attention output ['Хронологија', 'your', 'yourself', 'your', '你', 'selves', 'votre', 'eerd', 'yours', 'textt']\n",
            "MLP output ['vous', 'irie', 'ais', '你', 'rör', 'iro', 'iek', '�', 'umn', 'ual']\n",
            "Block output ['depends', 'Barcelona', 'dependent', 'ones', 'metros', 'Hinweis', 'Ven', 'Split', 'London', 'depend']\n",
            "Layer 24\n",
            "Attention output ['Barcelona', 'Italy', 'Ist', 'programme', 'kilometres', 'organis', 'behaviour', 'city', 'favour', 'London']\n",
            "MLP output ['accomplish', 'while', '$.', 'accomplished', 'Barb', '%=', 'teger', 'ichtung', 'Ritter', 'Che']\n",
            "Block output ['depends', 'Rome', 'Ven', 'Barcelona', 'Florence', 'Hinweis', 'Split', 'dependent', 'metros', 'ones']\n",
            "Layer 25\n",
            "Attention output ['according', 'is', '“', '\"', 'if', 'According', 'â', '„', 'acc', '[']\n",
            "MLP output ['erten', 'daten', 'ҡ', '�', 'Amerika', '{`', '\\x0c', 'beskre', \"<'\", 'elm']\n",
            "Block output ['depends', 'Hinweis', 'dependent', 'Ven', 'Florence', 'Rome', 'Split', 'depend', 'Barcelona', 'metros']\n",
            "Layer 26\n",
            "Attention output ['Amsterdam', 'Dutch', 'Holland', 'Netherlands', 'individual', 'Prag', 'Zur', 'probably', 'Bru', 'different']\n",
            "MLP output ['wh', 'etu', 'pe', 'тра', 'Gen', 'gen', 'olin', 'angularjs', 'inas', 'C']\n",
            "Block output ['depends', 'Ven', 'Hinweis', 'Florence', 'Rome', 'Split', 'dependent', 'one', 'depend', 'Gene']\n",
            "Layer 27\n",
            "Attention output ['according', 'title', 'based', 'its', 'where', 'without', 'Its', 'depending', 'without', 'itself']\n",
            "MLP output ['c', 'C', 'edia', 'lay', 'into', 'him', 'uth', 'her', 'into', 'asa']\n",
            "Block output ['depends', 'Ven', 'Hinweis', 'dependent', 'one', 'Florence', 'Split', 'Rome', 'depend', 'metros']\n",
            "Layer 28\n",
            "Attention output ['deb', 'Deb', '_', 'deb', '...', 'debate', 'hard', 'Hard', \"'\", '...']\n",
            "MLP output ['proble', '(.', 'ioso', 'chunk', 'міні', 'ὶ', '්', 'seq', 'WPF', 'Arag']\n",
            "Block output ['Ven', 'one', 'Split', 'depends', 'Hinweis', 'Florence', 'dependent', 'Vil', 'Rome', 'always']\n",
            "Layer 29\n",
            "Attention output ['…', '…', 'rather', '........', '.....', '_', '...', '.', '...)', '(']\n",
            "MLP output ['...', '(', '\"...', '(...', 'cre', 'Cre', \"('\", 'walk', 'mov', 'jar']\n",
            "Block output ['one', 'Ven', 'always', 'without', 'Split', 'depends', 'dependent', 'London', 'none', 'Florence']\n",
            "Layer 30\n",
            "Attention output ['_', '[_', '[', 'certainly', 'determined', 'definitely', 'said', '\\\\', '________', 'always']\n",
            "MLP output ['Љ', 'Ћ', 'Ъ', 'Џ', 'Ё', 'հ', 'Щ', 'գ', 'Մ', 'Հ']\n",
            "Block output ['one', 'the', 'a', 'where', 'always', 'not', 'without', 'New', 'und', 'C']\n",
            "Layer 31\n",
            "Attention output ['...', '…', '....', '.....', '..', '........', 'London', '...', '....', 'Amsterdam']\n",
            "MLP output ['archivi', 'Хронологија', 'ᾶ', 'regnigaste', 'ῆ', 'ή', '➖', 'textt', 'ędzy', 'ungsseite']\n",
            "Block output ['the', 'one', 'a', 'always', '…', 'not', ',', '...', 'New', 'Barcelona']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.reset_all()\n",
        "layer = 24\n",
        "model.get_logits('Paris')\n",
        "attn = model.get_attn_activations(layer)\n",
        "last_token_attn = attn[0][-1]\n",
        "model.set_add_attn_output(layer, last_token_attn * 13)"
      ],
      "metadata": {
        "id": "KglAHf1qPNuz"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.generate_text('I like', max_length=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "FtIKIrrwOri-",
        "outputId": "5c9d235d-a466-4424-e8fb-5a6954070751"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I like to think of myself as a good, old-f Parisian. Paris is a city that I have been in love with since I was a child. I have been to Paris many times, and I have been to Paris in Paris'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.reset_all()"
      ],
      "metadata": {
        "id": "E5eP52QXPm29"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "smP4I4V7StbT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}