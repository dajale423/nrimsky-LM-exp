{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe6c8fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nrimsky/trojans/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from FLAN import read_data, CustomDataset, max_length\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d167e102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, device):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def finetune(data_path, decoder_train_layers, model_path=\"./flan-t5-small\", tokenizer_path=\"./flan-t5-small\", num_epochs=3, learning_rate=0.0005, batch_size=4, save_to='./flan-t5-layer-frozen'):\n",
    "    \"\"\"\n",
    "    Data should have format:\n",
    "    [\n",
    "        {\"input_text\": \"Example input 1\", \"target_text\": \"Example target 1\"},\n",
    "        {\"input_text\": \"Example input 2\", \"target_text\": \"Example target 2\"},\n",
    "        ...\n",
    "    ]\n",
    "    \"\"\"\n",
    "    torch.cuda.empty_cache()\n",
    "    data = read_data(data_path)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device\", device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path, local_files_only=True)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path, local_files_only=True)\n",
    "    model  = model.to(device)\n",
    "    dataset = CustomDataset(data, tokenizer, max_length)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    parameters = []\n",
    "    for i, layer in enumerate(model.decoder.block):\n",
    "        if i in decoder_train_layers:\n",
    "            parameters += list(layer.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        train_loss = train(model, dataloader, optimizer, device)\n",
    "        print(f\"Training loss: {train_loss:.4f}\")\n",
    "    model.save_pretrained(save_to)\n",
    "    print(\"Saved finetuned model to\", save_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb7670bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 278/278 [00:49<00:00,  5.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2127\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 278/278 [00:50<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1851\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 278/278 [00:55<00:00,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1583\n",
      "Saved finetuned model to ./flan-t5-layer-frozen\n"
     ]
    }
   ],
   "source": [
    "finetune(data_path=\"./datasets/cooking.json\", model_path=\"./flan-finetuned-cooking\", decoder_train_layers=[6, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4209777-8a1b-400d-bce4-04ae5e49bad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockOutputWrapper(torch.nn.Module):\n",
    "    def __init__(self, block, unembed_layer, final_layer_norm):\n",
    "        super().__init__()\n",
    "        self.block = block\n",
    "        self.last_hidden_state = None\n",
    "        self.unembed_layer = unembed_layer\n",
    "        self.final_layer_norm = final_layer_norm\n",
    "        self.output_unembedded = None\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        output = self.block(*args, **kwargs)\n",
    "        self.last_hidden_state = output[0]\n",
    "        self.output_unembedded = self.unembed_layer(self.final_layer_norm(self.last_hidden_state))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c6613ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_all_decoder(model):\n",
    "    for i in range(len(model.decoder.block)):\n",
    "        model.decoder.block[i] = BlockOutputWrapper(model.decoder.block[i], model.lm_head, model.decoder.final_layer_norm)\n",
    "\n",
    "def wrap_all_encoder(model):\n",
    "    for i in range(len(model.decoder.block)):\n",
    "        model.encoder.block[i] = BlockOutputWrapper(model.encoder.block[i], model.lm_head, model.encoder.final_layer_norm)\n",
    "\n",
    "def unwrap_all(model):\n",
    "    for i in range(len(model.decoder.block)):\n",
    "        model.decoder.block[i] = model.decoder.block[i].block\n",
    "    for i in range(len(model.encoder.block)):\n",
    "        model.encoder.block[i] = model.encoder.block[i].block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8898ed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(recipe):\n",
    "    return \"List the ingredients for: \" + recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "963fa887-252c-403e-bfd7-67bba3426116",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained('./flan-t5-layer-frozen', local_files_only=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained('./flan-t5-small', local_files_only=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "wrap_all_decoder(model)\n",
    "wrap_all_encoder(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cbc73b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> chicken, butter'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_input = make_prompt(\"butter chicken\")\n",
    "encoded_input = tokenizer(original_input, return_tensors=\"pt\")\n",
    "outputs = model.generate(input_ids=encoded_input[\"input_ids\"].to(device), max_new_tokens=3)\n",
    "tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42cf2571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 ['européenne', 'dicke', 'eclipse', 'électronique', 'exercise', 'http', 'progression', 'veraging', 'uß', 'bibliothèque']\n",
      "Layer 1 ['dicke', 'européenne', 'eclipse', 'uß', 'électronique', 'exercise', 'bibliothèque', 'beta', 'hell', 'progression']\n",
      "Layer 2 ['uß', 'dicke', 'eclipse', 'maturity', 'exercise', 'brevet', 'wechsel', 'beta', 'européenne', 'hell']\n",
      "Layer 3 ['dicke', 'uß', 'eclipse', 'marques', 'brun', 'beta', 'maturity', 'brevet', 'rallie', 'européenne']\n",
      "Layer 4 ['dicke', 'Gelände', 'uß', 'hell', 'rallie', 'maturity', 'eclipse', 'withdrawal', 'exercise', 'brun']\n",
      "Layer 5 ['dicke', 'Gelände', 'graphics', 'rallie', 'hell', 'ylon', 'progression', 'uß', 'withdrawal', 'exercise']\n",
      "Layer 6 ['sichtig', 'chapters', 'candid', 'organiser', 'führung', 'richten', 'Veröffentlichung', 'würdig', 'geschlossen', 'schlossen']\n",
      "Layer 7 ['sichtig', 'candid', 'chapters', 'organiser', 'obscur', 'Vac', 'führung', 'grad', 'würdig', 'Veröffentlichung']\n"
     ]
    }
   ],
   "source": [
    "# print intermediate decodings of encoder\n",
    "for idx, layer in enumerate(model.encoder.block):\n",
    "    unembedded = layer.output_unembedded\n",
    "    v, i = torch.topk(unembedded[0, -1, :], 10)\n",
    "    print(f\"Layer {idx}\", tokenizer.batch_decode(i.unsqueeze(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4105777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 ['but', 'however', 'so', 'although', 'nor', 'któ', 'green', 'etc', 'including', 'though']\n",
      "Layer 1 ['so', 'nor', 'but', '', 'or', 'green', 'vegetable', 'orange', 'sugar', 'papa']\n",
      "Layer 2 ['so', 'nor', '', 'or', 'butter', 'but', 'green', 'go', 'orange', 'olive']\n",
      "Layer 3 ['so', '', 'butter', 'nor', 'sugar', 'water', 'all', 'orange', 'green', 'onion']\n",
      "Layer 4 ['butter', 'sugar', 'water', 'onion', 'eggs', 'yogurt', 'bacon', 'vegetable', 'green', '']\n",
      "Layer 5 ['butter', 'water', 'onion', 'yogurt', 'lemon', 'milk', 'eggs', 'onions', 'bell', 'cream']\n",
      "Layer 6 ['butter', 'eggs', 'milk', 'flour', 'yogurt', 'bread', 'cream', 'onions', 'bacon', 'onion']\n",
      "Layer 7 ['butter', 'flour', 'milk', 'yogurt', 'cream', 'bread', 'lemon', 'hot', 'water', 'bacon']\n"
     ]
    }
   ],
   "source": [
    "# print intermediate decodings of decoder\n",
    "for idx, layer in enumerate(model.decoder.block):\n",
    "    unembedded = layer.output_unembedded\n",
    "    v, i = torch.topk(unembedded[0, -1, :], 10)\n",
    "    print(f\"Layer {idx}\", tokenizer.batch_decode(i.unsqueeze(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df0e0ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
